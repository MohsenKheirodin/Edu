{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdb050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03609f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Defining Tensors\n",
    "# d0 = tf.ones((1,))      # 0D tensor\n",
    "# d1 = tf.ones((2,))      # 1D tensor\n",
    "# d2 = tf.ones((2,2))     # 2D tensor\n",
    "# d3 = tf.ones((2,2,2))   # 3D tensor\n",
    "# print(d3.numpy())\n",
    "\n",
    "# # Defining Constants\n",
    "# a = tf.constant(3, shape = [2, 3])\n",
    "# b = tf.constant([1, 3, 5, 2], shape = [2, 2])\n",
    "\n",
    "# # convenience functions for Constants\n",
    "# a1 = tf.constant([1, 2, 3])\n",
    "# a2 = tf.zeros([2, 2])\n",
    "# a3 = tf.zeros_like(b)\n",
    "# a4 = tf.ones([2, 3])\n",
    "# a5 = tf.ones_like(b)\n",
    "# a6 = tf.fill([3, 5], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6226a3ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a Variable\n",
    "# x = tf.Variable([1, 2, 3, 4, 5, 6], dtype = tf.float32)\n",
    "# y = tf.Variable([1, 2, 3, 4, 5, 6], dtype = tf.int16)\n",
    "# b = tf.constant(2, tf.float32)\n",
    "# c0 = tf.multiply(x, b)\n",
    "# c1 = b * x\n",
    "# print(c0)\n",
    "# print(c1)\n",
    "\n",
    "# # Convert the credit_numpy array into a tensorflow constant\n",
    "# credit_constant = constant(credit_numpy)\n",
    "# # Convert A1 to a numpy array and assign it to B1\n",
    "# B1 = A1.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "178c5a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Basic Operations\n",
    "# from tensorflow import constant, add, matmul, multiply, ones, reduce_sum\n",
    "# A0 = constant([1])\n",
    "# B0 = constant([2])\n",
    "# A1 = constant([1, 3])\n",
    "# B1 = constant([2, 4])\n",
    "# A2 = constant([[1, 2], [3, 4]])\n",
    "# B2 = constant([[5, 6], [7, 8]])\n",
    "\n",
    "# # Elementwise Addition\n",
    "# C0 = add(A0, B0) \n",
    "# C1 = add(A1, B1)\n",
    "# C2 = add(A2, B2)\n",
    "\n",
    "# # Elementwise Multiplication\n",
    "# D0 = multiply(A2, B2)\n",
    "# # Matrix Multiplication\n",
    "# D1 = matmul(A2, B2)\n",
    "\n",
    "# # Summing over tensors\n",
    "# A = ones([2, 3, 4])\n",
    "# B = reduce_sum(A)\n",
    "# B0 = reduce_sum(A,0)\n",
    "# B1 = reduce_sum(A,1)\n",
    "# B2 = reduce_sum(A,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "137b3708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Adcanced Operators\n",
    "# # Gradinet\n",
    "# import tensorflow as tf\n",
    "# x = tf.Variable(-2.0)\n",
    "# with tf.GradientTape() as tape:\n",
    "#     tape.watch(x)\n",
    "#     y = tf.multiply(x, x)\n",
    "\n",
    "# g = tape.gradient(y, x)\n",
    "# print(g.numpy())\n",
    "\n",
    "# # Reshape\n",
    "# gray = tf.random.uniform([2, 2], maxval= 255, dtype='int32')\n",
    "# gray = tf.reshape(gray, [2*2, 1])\n",
    "\n",
    "# colors = tf.random.uniform([2, 2, 3], maxval= 255, dtype='int32')\n",
    "# colors = tf.reshape(colors, [2*2, 3])\n",
    "# colors = tf.reshape(colors, [2*2*3,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6938abc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Importing Data\n",
    "# housing = pd.read_csv('file1.csv')\n",
    "# # Parameters : sep (default = ',')  ||  delim_whitspace ||  encoding\n",
    "# housing = no.array(housing)\n",
    "\n",
    "# # Setting Data Types\n",
    "# price = np.array(housing['price'], np.float32)\n",
    "# waterfront = np.array(housing['waterfront'], np.bool)\n",
    "\n",
    "# # or (second method)\n",
    "# price = tf.cast(housing['price'], tf.float32)\n",
    "# waterfront = tf.cast(housing['waterfront'], tf.bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "287f3454",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loss Functions\n",
    "# from tensorflow import keras\n",
    "# loss = tf.keras.losses.MSE(targets, predictions) # others: MAE, Huber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c816bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A linear regression sample\n",
    "# price = np.array(housing['price'], np.float32)\n",
    "# size = np.array(housing['sqft'], np.float32)\n",
    "\n",
    "# intercept = tf.Variable(0.1, np.float32)\n",
    "# slope = tf.Variable(0.1, np.float32)\n",
    "\n",
    "# def Linear_reg (intercept, slope, features = size):\n",
    "#     return intercept + features * slope\n",
    "# def loss_function(intercept, slope, target = price, features = size):\n",
    "#     predictions = Linear_reg(intercept, slope)\n",
    "#     return tf.keras.losses.mse(target, predictions)\n",
    "\n",
    "# opt = tf.keras.optimizers.Adam()\n",
    "\n",
    "# for j in range(1000):\n",
    "#     opt.minimize(lambda: loss_function(intercept, slope), var_list = [intercept, slope])\n",
    "#     print(loss_function(intercept, slope))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e35b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Batch Training\n",
    "# for batch in pd.read_csv('file1.csv', chunksize=5):\n",
    "#     price = np.array(batch['price'], np.float32)\n",
    "#     size = np.array(batch['size'], np.float32)\n",
    "\n",
    "# # Then we send this variables to the codes in the previous block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0339452b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Dense Layers\n",
    "# inputs = tf.constant(5.0, tf.float32)\n",
    "# # the following code does not run without errors, for solving the problem you should remove the last paranthesis, which is not true I guess.\n",
    "# dense1 = tf.keras.layers.Dense(10, activation = 'sigmoid')(inputs)\n",
    "# dense2 = tf.keras.layers.Dense(5, activation = 'sigmoid')(dense1)\n",
    "\n",
    "# # lower level codes\n",
    "# # prod = matmul(inputs, weights)\n",
    "# # dense1_2 = tf.keras.activations.sigmoid(prod)\n",
    "# # other activations are relu and sigmoid (for classification problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25a1a726",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of a Forward Prop (classification problem)\n",
    "# inputs = constant(borrower_features, float32)\n",
    "# dense1 = keras.layers.Dense(10, activation='sigmoid')(inputs)\n",
    "# dense2 = keras.layers.Dense(8, activation='relu')(dense1)\n",
    "# outputs = keras.layers.Dense(6, activation='softmax')(dense2)\n",
    "# print(outputs.numpy()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eacebea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers : SGD, RMSprop, Adam\n",
    "# Example of comparing optimizer parameters. The code does not work\n",
    "# Initialize x_1 and x_2\n",
    "\n",
    "# x_1 = tf.Variable(0.05,tf.float32)\n",
    "# x_2 = tf.Variable(0.05,tf.float32)\n",
    "\n",
    "# opt_1 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.99)\n",
    "# opt_2 = keras.optimizers.RMSprop(learning_rate=0.01, momentum=0.00)\n",
    "\n",
    "# for j in range(100):\n",
    "# \topt_1.minimize(lambda: loss_function(x_1), var_list=[x_1])\n",
    "# \topt_1.minimize(lambda: loss_function(x_2), var_list=[x_2])\n",
    "\n",
    "# print(x_1.numpy(), x_2.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "72667603",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initialzing & Dropouts\n",
    "# weights1 = tf.Variable(tf.random.normal([200, 200]))\n",
    "# weights2 = tf.Variable(tf.random.truncated_normal([200, 200]))\n",
    "\n",
    "# # high level\n",
    "# dense2 = keras.layers.Dense(8, activation='relu', kernel_initializer = 'zeros')\n",
    "# # dense2 = keras.layers.Dense(8, activation='relu', kernel_initializer = 'zeros')(dens1)\n",
    "\n",
    "# # Dropouts\n",
    "# dropout1 = keras.layers.Dropout(0.25)(dense2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95dc0830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# # Define the model\n",
    "# def model(w1, b1, w2, b2, features = borrower_features):\n",
    "# \tlayer1 = keras.activations.relu(matmul(features, w1) + b1)\n",
    "# \tdropout = keras.layers.Dropout(0.25)(layer1)\n",
    "# \treturn keras.activations.sigmoid(matmul(dropout, w2) + b2)\n",
    "\n",
    "# # Define the loss function\n",
    "# def loss_function(w1, b1, w2, b2, features = borrower_features, targets = default):\n",
    "# \tpredictions = model(w1, b1, w2, b2)\n",
    "# \treturn keras.losses.binary_crossentropy(targets, predictions)\n",
    "\n",
    "# for j in range(100):\n",
    "# \topt.minimize(lambda: loss_function(w1, b1, w2, b2), \n",
    "#                  var_list=[w1, b1, w2, b2])\n",
    "\n",
    "# model_predictions = model(w1, b1, w2, b2, test_features)\n",
    "# confusion_matrix(test_targets, model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d895d296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Creating a model (Sequential or Functional) \n",
    "# # 1. Sequential\n",
    "\n",
    "# from tensorflow import keras\n",
    "# model = keras.Sequential()\n",
    "# model.add(keras.layers.Dense(16, activation = 'relu', input_shape = (28*28,)))\n",
    "# model.add(keras.layers.Dense(8, activation = 'relu'))\n",
    "# model.add(keras.layers.Dense(4, activation = 'softmax'))\n",
    "# model.compile('adam', loss = \"categorical_crossentropy\")\n",
    "# model.compile('adam', loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "# model.compile(optimizer=keras.optimizers.Adam(lr=0.001), loss = \"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c05bf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 2. Functional\n",
    "# model1_input = tf.keras.Input(shape= (28*28,))\n",
    "# model2_input = tf.keras.Input(shape= (10,))\n",
    "\n",
    "# model1_layer1 = tf.keras.layers.Dense(12, activation = \"relu\")(model1_input)\n",
    "# model1_layer2 = tf.keras.layers.Dense(4, activation = \"softmax\")(model1_layer1)\n",
    "\n",
    "# model2_layer1 = tf.keras.layers.Dense(12, activation = \"relu\")(model2_input)\n",
    "# model2_layer2 = tf.keras.layers.Dense(4, activation = \"softmax\")(model2_layer1)\n",
    "\n",
    "# merged = tf.keras.layers.add([model1_layer2, model2_layer2])\n",
    "# model = tf.keras.Model(inputs = [model1_input, model2_input], outputs = merged)\n",
    "# model.compile('adam', loss = \"categorical_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bae14633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit Function and evaluation (continuing the sequential example)\n",
    "# model.fit(image_features, image_labels)\n",
    "# model.fit(image_features, image_labels, epochs=10, validation_split=0.2)\n",
    "# model.evaluate(train_features, train_labels)\n",
    "# model.evaluate(test_features, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab325875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Estimator APIs\n",
    "# # define a feature column\n",
    "# size = tf.feature_column.numeric_column('size')\n",
    "# # define a categorical feature column\n",
    "# rooms = tf.feature_column.categorical_column_with_vocabulary_list(\"rooms\", [\"1\", \"2\", \"3\", \"4\", \"5\"])\n",
    "# # create feature column list\n",
    "# feature_list = [size, rooms]\n",
    "# # Define a matrix feature column\n",
    "# # feature_list = [tf.feature_column.numeric_column('image', shape=(784,))]\n",
    "\n",
    "# def input_fn():\n",
    "#     features = {\"size\" : [1000, 1500, 1800], \"rooms\": [1, 2, 3]}\n",
    "#     labels = [220000, 250000, 320000]\n",
    "#     return features, labels\n",
    "\n",
    "# model0 = tf.estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[10, 6, 6, 3])\n",
    "# model0.train(input_fn, steps=20)\n",
    "\n",
    "# model1 = estimator.DNNClassifier(feature_columns = feature_list, hidden_units = [32, 16, 8], n_classes = 4)\n",
    "# model1.train(input_fn, steps = 20)\n",
    "\n",
    "# # # https://www.tensorflow.org/guide/estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "21f89a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\KHEIRO~1\\AppData\\Local\\Temp\\tmph31zy_8w\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\KHEIRO~1\\\\AppData\\\\Local\\\\Temp\\\\tmph31zy_8w', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'housing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9988\\1392002051.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDNNRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeature_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeature_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhidden_units\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Kheiroddin\\anacondaa\\envs\\tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m       \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Loss for final step: %s.'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kheiroddin\\anacondaa\\envs\\tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1184\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1185\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1186\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1187\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1188\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kheiroddin\\anacondaa\\envs\\tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[1;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[0;32m   1210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1211\u001b[0m       features, labels, input_hooks = (\n\u001b[1;32m-> 1212\u001b[1;33m           self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n\u001b[0m\u001b[0;32m   1213\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n",
      "\u001b[1;32mc:\\Users\\Kheiroddin\\anacondaa\\envs\\tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_get_features_and_labels_from_input_fn\u001b[1;34m(self, input_fn, mode)\u001b[0m\n\u001b[0;32m   1046\u001b[0m     \u001b[1;34m\"\"\"Extracts the `features` and labels from return values of `input_fn`.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1047\u001b[0m     return estimator_util.parse_input_fn_result(\n\u001b[1;32m-> 1048\u001b[1;33m         self._call_input_fn(input_fn, mode))\n\u001b[0m\u001b[0;32m   1049\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1050\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extract_batch_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreds_evaluated\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kheiroddin\\anacondaa\\envs\\tf\\lib\\site-packages\\tensorflow_estimator\\python\\estimator\\estimator.py\u001b[0m in \u001b[0;36m_call_input_fn\u001b[1;34m(self, input_fn, mode, input_context)\u001b[0m\n\u001b[0;32m   1139\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'input_context'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1140\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'/cpu:0'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1141\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_model_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_9988\\1392002051.py\u001b[0m in \u001b[0;36minput_fn\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhousing\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'price'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n\u001b[0;32m      9\u001b[0m                 'bathrooms':np.array(housing['bathrooms'])}\n",
      "\u001b[1;31mNameError\u001b[0m: name 'housing' is not defined"
     ]
    }
   ],
   "source": [
    "# # Another Example of Estimators\n",
    "# bedrooms = tf.feature_column.numeric_column(\"bedrooms\")\n",
    "# bathrooms = tf.feature_column.numeric_column(\"bathrooms\")\n",
    "# feature_list = [bedrooms, bathrooms]\n",
    "\n",
    "# def input_fn():\n",
    "# \tlabels = np.array(housing['price'])\n",
    "# \tfeatures = {'bedrooms':np.array(housing['bedrooms']), \n",
    "#                 'bathrooms':np.array(housing['bathrooms'])}\n",
    "# \treturn features, labels\n",
    "\n",
    "# model = tf.estimator.DNNRegressor(feature_columns=feature_list, hidden_units=[2,2])\n",
    "# model.train(input_fn, steps=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c339d645",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
