{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ecdb050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "721ead53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # inner join: the common rows will remain\n",
    "# Cities1 = pd.read_csv('Cities1.csv')            \n",
    "# Cities2 = pd.read_csv('Cities2.csv')         \n",
    "# wards_census1 = Cities1.merge(Cities2, on = 'city')   \n",
    "# wards_census2 = Cities1.merge(Cities2, on = 'city', suffixes = ('_ward','_cen'))\n",
    "# print(wards_census2)\n",
    "\n",
    "\n",
    "# # one-to-many relationship\n",
    "# # in a one-to-one relationship every row in the first table is related to one and only one row in the other one\n",
    "# Cities3 = pd.read_csv('Cities3.csv')            \n",
    "# wards_census3 = Cities1.merge(Cities3, on = 'city', suffixes = ('_ward','_cen'))\n",
    "# print(wards_census3)\n",
    "# print(wards_census3.loc[wards_census3['city']=='Tehran',['money','pop']])\n",
    "\n",
    "# # .value_count() : gives you the number of a column in descending order\n",
    "# # for example: print(taxi_own_veh['fuel_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b573e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# licenses_owners = licenses.merge(biz_owners, on = 'account')\n",
    "\n",
    "# # Group the results by title then count the number of accounts\n",
    "# counted_df = licenses_owners.groupby('title').agg({'account':'count'})\n",
    "# sorted_df = counted_df.sort_values('account', ascending = False)\n",
    "# print(sorted_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac34804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merging Multiple DataFrames\n",
    "# # we can merge on multiple columns\n",
    "# wards_census3 = Cities1.merge(Cities3, on = ['city','row'], suffixes = ('_ward','_cen'))\n",
    "# print(wards_census3)\n",
    "\n",
    "# grants_licenses_ward = grant.merge(license,on = ['address', 'zip']).merge(wards,on = 'ward', suffixes = ('_bus','ward'))\n",
    "# # you can contuniue this by merging more than three tables\n",
    "# grants_licenses_ward.groupby('ward').agg('sum').plot(kind = 'bar', y = 'grant')\n",
    "\n",
    "# # Example. The code does not work\n",
    "# ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "# \t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "# filter_criteria = ((ridership_cal_stations['month'] == 7) \n",
    "#                    & (ridership_cal_stations['day_type'] == \"Weekday\") \n",
    "#                    & (ridership_cal_stations['station_name'] == \"Wilson\"))\n",
    "\n",
    "# print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b513c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Examples. The code does not work\n",
    "# # Example 1\n",
    "# ridership_cal_stations = ridership.merge(cal, on=['year','month','day']) \\\n",
    "# \t\t\t\t\t\t\t.merge(stations, on='station_id')\n",
    "\n",
    "# filter_criteria = ((ridership_cal_stations['month'] == 7) \n",
    "#                    & (ridership_cal_stations['day_type'] == \"Weekday\") \n",
    "#                    & (ridership_cal_stations['station_name'] == \"Wilson\"))\n",
    "\n",
    "# print(ridership_cal_stations.loc[filter_criteria, 'rides'].sum())\n",
    "\n",
    "# # Example 2\n",
    "# licenses_zip_ward = licenses.merge(zip_demo, on = 'zip') \\\n",
    "#             \t\t\t.merge(wards, on = 'ward')\n",
    "\n",
    "# print(licenses_zip_ward.groupby('alderman').agg({'income':'median'}))\n",
    "\n",
    "# Example 3\n",
    "# # Merge land_use and census and merge result with licenses including suffixes\n",
    "# land_cen_lic = land_use.merge(census, on='ward') \\\n",
    "#                     .merge(licenses, on='ward', suffixes=('_cen','_lic'))\n",
    "\n",
    "# # Group by ward, pop_2010, and vacant, then count the # of accounts\n",
    "# pop_vac_lic = land_cen_lic.groupby(['ward','pop_2010','vacant'], \n",
    "#                                    as_index=False).agg({'account':'count'})\n",
    "\n",
    "# # Sort pop_vac_lic and print the results\n",
    "# sorted_pop_vac_lic = pop_vac_lic.sort_values(['vacant', 'account', 'pop_2010'], \n",
    "#                                              ascending=[False,True,True])\n",
    "\n",
    "# # Print the top few rows of sorted_pop_vac_lic\n",
    "# print(sorted_pop_vac_lic.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "889b522d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Left Join\n",
    "# Cities1 = pd.read_csv('Cities1.csv')            \n",
    "# Cities2 = pd.read_csv('Cities2.csv')         \n",
    "# wards_census4 = Cities1.merge(Cities2, on = 'city', how = 'left')\n",
    "# print(wards_census4)\n",
    "# print(Cities1)\n",
    "# print(wards_census4['range'].isnull().sum())\n",
    "\n",
    "# # Similarly we have right join\n",
    "# wards_census5 = Cities2.merge(Cities1, on = 'city', how = 'right')  # Similar rows to wards_census4 but different order of columns\n",
    "# # we can have seperate left_on and right_on\n",
    "# tv_movies = movies.merge(tv_genre, how = 'right', left_on = 'id', right_on = 'movie_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee4fdbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Outer join\n",
    "# wards_census6 = Cities1.merge(Cities2, on = 'city', how = 'outer', suffixes=('A','B'))\n",
    "# print(wards_census6)\n",
    "\n",
    "# # An Example\n",
    "# # Merge iron_1_actors to iron_2_actors on id with outer join using suffixes\n",
    "# iron_1_and_2 = iron_1_actors.merge(iron_2_actors,\n",
    "#                                      how='outer',\n",
    "#                                      on = 'id',\n",
    "#                                      suffixes=('_1','_2'))\n",
    "\n",
    "# # Create an index that returns true if name_1 or name_2 are null\n",
    "# m = ((iron_1_and_2['name_1'].isnull()) | \n",
    "#      (iron_1_and_2['name_2'].isnull()))\n",
    "\n",
    "# # Print the first few rows of iron_1_and_2\n",
    "# print(iron_1_and_2[m].head())\n",
    "\n",
    "# Note: the on column can be the index too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63981aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Merging a Table with itself\n",
    "# original_sequels = sequels.merge(sequels, left_on = 'seq', right_on = 'id', suffixes = ('_org', '_seq'))\n",
    "# print(original_sequels[,['title_org','title_seq']])\n",
    "# # There are other kinds of merging here, again (such as left, right, ...)\n",
    "# # They can be used for: Hierarchical relationship, Sequential relationship, Graph Data\n",
    "# # default of how in merge is \"inner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e48a443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1\n",
    "# # Merge the crews table to itself\n",
    "# crews_self_merged = crews.merge(crews, on='id', how='inner',\n",
    "#                                 suffixes=('_dir','_crew'))\n",
    "\n",
    "# # Create a boolean index to select the appropriate rows\n",
    "# boolean_filter = ((crews_self_merged['job_dir'] == 'Director') & \n",
    "#                   (crews_self_merged['job_crew'] != 'Director'))\n",
    "# direct_crews = crews_self_merged[boolean_filter]\n",
    "\n",
    "# # Print the first few rows of direct_crews\n",
    "# print(direct_crews.head())\n",
    "\n",
    "\n",
    "# Example 2\n",
    "# # Merge sequels and financials on index id\n",
    "# sequels_fin = sequels.merge(financials, on='id', how='left')\n",
    "\n",
    "# # Self merge with suffixes as inner join with left on sequel and right on id\n",
    "# orig_seq = sequels_fin.merge(sequels_fin, how='inner', left_on='sequel', \n",
    "#                              right_on='id', right_index=True,\n",
    "#                              suffixes=('_org','_seq'))\n",
    "\n",
    "# # Add calculation to subtract revenue_org from revenue_seq \n",
    "# orig_seq['diff'] = orig_seq['revenue_seq'] - orig_seq['revenue_org']\n",
    "\n",
    "# # Select the title_org, title_seq, and diff \n",
    "# titles_diff = orig_seq[['title_org','title_seq','diff']]\n",
    "\n",
    "# # Print the first rows of the sorted titles_diff\n",
    "# print(titles_diff.sort_values('diff', ascending = False).head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "812db6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Filtering\n",
    "# # A) Semi Join\n",
    "# genres_tracks = genre.merge(top_tracks, on = 'gid')        # inner join\n",
    "# top_genres = genres[genres['gid'].isin(genres_tracks['gid'])]\n",
    "\n",
    "# # B) Anti Join\n",
    "# genres_tracks = Cities1.merge(Cities2, on = 'city', how = 'left', indicator = True)    # the function of indicator column\n",
    "# gid_list = genres_tracks.loc[genres_tracks['_merge'] == 'left_only','city']\n",
    "# non_top_genres = Cities1[Cities1['city'].isin(gid_list)]\n",
    "# print(non_top_genres)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d9d0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Examples of Filtering\n",
    "# # Example 1\n",
    "# empl_cust = employees.merge(top_cust, on='srid', \n",
    "#                             how='left', indicator=True)\n",
    "# srid_list = empl_cust.loc[empl_cust['_merge'] == 'left_only', 'srid']\n",
    "# print(employees[employees['srid'].isin(srid_list)])\n",
    "\n",
    "# # Example 2\n",
    "# # Merge the non_mus_tck and top_invoices tables on tid\n",
    "# tracks_invoices = non_mus_tcks.merge(top_invoices,on = 'tid')\n",
    "\n",
    "# # Use .isin() to subset non_mus_tcks to rows with tid in tracks_invoices\n",
    "# top_tracks = non_mus_tcks[non_mus_tcks['tid'].isin(tracks_invoices['tid'])]\n",
    "\n",
    "# # Group the top_tracks by gid and count the tid rows\n",
    "# cnt_by_gid = top_tracks.groupby(['gid'], as_index=False).agg({'tid':'count'})\n",
    "\n",
    "# # Merge the genres table to cnt_by_gid on gid and print\n",
    "# print(cnt_by_gid.merge(genres, on = 'gid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e23c7151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concat : connect rows and not columns (like merge)\n",
    "# # consider three tables with same columns, we can concat them by:\n",
    "# pd.concat([inv1, inv2, inv3])   # default axis = 0, which makes concat vertically (zire ham)\n",
    "# pd.concat([inv1, inv2, inv3], ignore_index=True)  # ignoring the index\n",
    "# pd.concat([inv1, inv2, inv3], ignore_index=False, keys = ['jan','feb', 'mar'])  # designing the index\n",
    "# # when ignore_index = True: index goes from 0 to n-1\n",
    "# # if the columns are not equal, the same code will work, and we will have some NaN\n",
    "# # But we can also remove the columns that do not exist in both tables.\n",
    "# pd.concat([inv1, inv2], join='inner')\n",
    "# # Sorting:\n",
    "# pd.concat([inv1, inv2], sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b4abe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example:\n",
    "# # Concatenate the tables and add keys\n",
    "# inv_jul_thr_sep = pd.concat([inv_jul, inv_aug, inv_sep], \n",
    "#                             keys=['7Jul','8Aug','9Sep'])\n",
    "\n",
    "# # Group the invoices by the index keys and find avg of the total column\n",
    "# avg_inv_by_month = inv_jul_thr_sep.groupby(level=0).agg({'total':'mean'})\n",
    "\n",
    "# # Bar plot of avg_inv_by_month\n",
    "# avg_inv_by_month.plot(kind='bar')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6db5a275",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validating the integrity of created tables\n",
    "# # .merge(validate = None), other possible input: 'one-to-one', 'one-to-many', 'many-to-one', 'many-to-many'\n",
    "# Cities1.merge(Cities3, on = 'city', validate ='one-to-one')    # if the condition does not hold, we face an error\n",
    "\n",
    "# # .concat(verify_integrity = False), check if there are two same indexes in the two tables\n",
    "# pd.concat([inv1, inv2], verify_integrity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4fd9c5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # merge_ordered(), when the result is ordered based on the on column\n",
    "# out1 = pd.merge_ordered(Cities1,Cities2,on = 'city', suffixes=('_1','_2'))\n",
    "# out2 = pd.merge_ordered(Cities1,Cities2,on = 'city', suffixes=('_1','_2'), fill_method='ffill')\n",
    "# print(out2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b60b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# # Use merge_ordered() to merge gdp and sp500, interpolate missing value\n",
    "# gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='year', right_on='date', \n",
    "#                              how='left',  fill_method='ffill')\n",
    "\n",
    "# # Subset the gdp and returns columns\n",
    "# gdp_returns = gdp_sp500[['gdp','returns']]\n",
    "\n",
    "# # Print gdp_returns correlation\n",
    "# print(gdp_returns.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad109a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # using merge_asof()\n",
    "# # similar features as merge_ordered, but match on the nearest key column and not exact match\n",
    "# # Merge on columns must be sorted\n",
    "# # Consider the daily trading information of two stocks, which their trading times do not necessarily match.\n",
    "# # output will be similar to left join\n",
    "# # good for acquiring sample data from a process or developing a training set\n",
    "\n",
    "# joint_data = pd.merge_asof(visa, ibm, on = 'date_time', suffixes = ['_visa','_ibm'])   \n",
    "# # Default: use the last near data of ibm (before each time step of visa data)\n",
    "# joint_data = pd.merge_asof(visa, ibm, on = 'date_time', suffixes = ['_visa','_ibm'], direction = 'forward')\n",
    "# # Default is backward\n",
    "# # We can also set the direction: nearest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1501da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1 (interesting plot form)\n",
    "# jpm_wells = pd.merge_asof(jpm,wells, on = 'date_time', suffixes=('', '_wells'),direction = 'nearest')\n",
    "# jpm_wells_bac = pd.merge_asof(jpm_wells,bac, on = 'date_time', suffixes=('_jpm', '_bac'), direction = 'nearest')\n",
    "# price_diffs = jpm_wells_bac.diff()\n",
    "# price_diffs.plot(y=['close_jpm', 'close_wells', 'close_bac'])\n",
    "# plt.show()\n",
    "\n",
    "# # Example 2\n",
    "# gdp_recession = pd.merge_asof(gdp,recession, on = 'date')\n",
    "# is_recession = ['r' if s=='recession' else 'g' for s in gdp_recession['econ_status']]\n",
    "# gdp_recession.plot(kind='bar', y='gdp', x='date', color=is_recession, rot=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f312eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # .query()\n",
    "# df = pd.read_csv('Sample1.csv')\n",
    "# df.query('pop>10 and year>75')      # we can use or either\n",
    "# df.query('city==\"tehran\" or (pop>10 and year<75)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cb8e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# gdp_pop = pd.merge_ordered(gdp, pop, on=['country','date'], fill_method='ffill')\n",
    "# gdp_pop['gdp_per_capita'] = gdp_pop['gdp'] / gdp_pop['pop']\n",
    "\n",
    "# # Pivot data so gdp_per_capita, where index is date and columns is country\n",
    "# gdp_pivot = gdp_pop.pivot_table('gdp_per_capita', 'date', 'country')\n",
    "# recent_gdp_pop = gdp_pivot.query('date>=\"1991-01-01\"')\n",
    "# recent_gdp_pop.plot(rot=90)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c227087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Melting (explanation about wide and long formats exist in reshaping file)\n",
    "# df = pd.read_csv('Sample4.csv')\n",
    "# melted_df1 = df.melt(id_vars='city')\n",
    "# melted_df2 = df.melt(id_vars='city', value_vars=['pop70','gdp60'], var_name='variables', value_name='values')\n",
    "# print(melted_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd296db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1\n",
    "# # unpivot everything besides the year column\n",
    "# ur_tall = ur_wide.melt(id_vars='year', var_name='month', value_name='unempl_rate')\n",
    "# ur_tall['date'] = pd.to_datetime(ur_tall['year'] + '-' + ur_tall['month'])\n",
    "# ur_sorted = ur_tall.sort_values('date', ascending = True)\n",
    "# ur_sorted.plot(x = 'date', y = 'unempl_rate')\n",
    "# plt.show()\n",
    "\n",
    "# # Example 2\n",
    "# # Use melt on ten_yr, unpivot everything besides the metric column\n",
    "# bond_perc = ten_yr.melt(id_vars='metric', var_name='date', value_name='close')\n",
    "\n",
    "# # Use query on bond_perc to select only the rows where metric=close\n",
    "# bond_perc_close = bond_perc.query('metric == \"close\"')\n",
    "\n",
    "# # Merge (ordered) dji and bond_perc_close on date with an inner join\n",
    "# dow_bond = pd.merge_ordered(dji, bond_perc_close, on='date', \n",
    "#                             suffixes=('_dow', '_bond'), how='inner')\n",
    "\n",
    "# # Plot only the close_dow and close_bond columns\n",
    "# dow_bond.plot(y=['close_dow', 'close_bond'], x='date', rot=90)\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
