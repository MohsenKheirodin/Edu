{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecdb050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20bacadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working with Time\n",
    "\n",
    "# from datetime import datetime\n",
    "# time_stamp = pd.Timestamp(datetime(2017, 1, 1))\n",
    "# print(pd.Timestamp(\"2017-01-01\") == time_stamp)\n",
    "# print(time_stamp.year)\n",
    "# print(time_stamp.day_name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "92d16d03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Initial operations and objects related to time\n",
    "\n",
    "# period = pd.Period('2017-01') # default is month end\n",
    "# period.asfreq('D')            # change frequency to daily\n",
    "# timee = period.to_timestamp()  # convert to time stamp\n",
    "# period = timee.to_period('M')   # convert again to period\n",
    "# print(period+2)\n",
    "# index = pd.date_range(start='2017-01-01', periods = 12, freq='M')\n",
    "# print(index)\n",
    "# print(index[0])\n",
    "# period2 = index.to_period\n",
    "# print(period2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cf70560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "\n",
    "# date_info = pd.DataFrame({'data':index}).info()\n",
    "# data = np.random.random(size =(12,2))\n",
    "# pd.DataFrame(data = data, index=index).info()\n",
    "\n",
    "# # Frequency aliases beside \"M\", \"D\": Hour: 'H', Day: 'D', Week: 'W', Month: 'M', Quarter: 'Q', Year: 'Y'\n",
    "# attributes (you can also access these pd.DataFrame() attributes):  (.second .minute .hour) \n",
    "#                         (.day .month . quarter .year) (.weekday .dayofweek .weekofyear .dayofyear)  \n",
    "\n",
    "# Explanation: create a sequence of dates using pd.date_range(). \n",
    "# You have also seen that each date in the resulting pd.DatetimeIndex is a pd.Timestamp with \n",
    "# various attributes that you can access to obtain information about the date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c558ca02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example\n",
    "# seven_days = pd.date_range(start = '2017-1-1', periods = 7, freq = 'D')\n",
    "# for day in seven_days:\n",
    "#     print(day.dayofweek, day.day_name())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1cae12df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Working with pandas\n",
    "\n",
    "# w = pd.read_csv(\"Sample for working with time.csv\")\n",
    "# w.date = pd.to_datetime(w.date)   # the date column format changed to datetime64\n",
    "# w.set_index('date', inplace= True)\n",
    "# w.price.plot(title = 'price')\n",
    "# plt.tight_layout(); plt.show()\n",
    "# w['2018'].info()\n",
    "# w['2018-03':'2019-01']\n",
    "# print(w.loc['2018-03-01', 'price'])\n",
    "# w.asfreq('D').info()  # set calendar day frequency\n",
    "# w.asfreq('D').head()  # There are some NANs because we are unsampling\n",
    "# w.asfreq('B').info()    # Business Days\n",
    "# w[w.price.isnull()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c59b6f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example. The code works\n",
    "# prices = pd.DataFrame()\n",
    "# for year in ['2017', '2018', '2019']:\n",
    "#     price_per_year = w.loc[year, [\"price\"]].reset_index(drop=True)\n",
    "#     price_per_year.rename(columns={\"price\": year}, inplace=True)\n",
    "#     prices = pd.concat([prices, price_per_year], axis=1)\n",
    "\n",
    "# # Plot prices\n",
    "# prices.plot(subplots = True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce8337a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift and lag and calculating return\n",
    "\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# fulad['one_shift'] = fulad.price.shift()\n",
    "# fulad['one_lag'] = fulad.price.shift(periods=-1)\n",
    "# fulad[['price', 'one_lag', 'one_shift']].tail(3)\n",
    "# fulad['change'] = fulad.price.div(fulad.one_shift) #.sub\n",
    "# fulad['change'] = fulad.change.sub(1).mul(100)\n",
    "# fulad['diff'] = fulad.price.diff()\n",
    "# fulad['return'] = fulad.price.pct_change().mul(100)\n",
    "# fulad[['price', 'change', 'return']].head(5)\n",
    "# fulad['return_3d'] = fulad.price.pct_change(periods = 3).mul(100)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "21a0fa7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# fulad = fulad.asfreq('B')\n",
    "# fulad['lagged'] = fulad.price.shift(periods=-90)\n",
    "# fulad['shifted'] = fulad.price.shift(periods = 90)\n",
    "# fulad.plot(subplots = True); plt.show()\n",
    "\n",
    "# # Example 2\n",
    "# fulad['shifted_30'] = fulad.price.shift(periods=30)\n",
    "# fulad['change_30'] = fulad.price.sub(fulad.shifted_30)\n",
    "# fulad['diff_30'] =  fulad.price.diff(30)\n",
    "# print(fulad.tail(5))\n",
    "# print(fulad.diff_30.sub(fulad.change_30).value_counts())\n",
    "\n",
    "# # Example 3\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# fulad['daily_return'] = fulad.price.pct_change().mul(100)\n",
    "# fulad['monthly_return'] = fulad.price.pct_change(30).mul(100)\n",
    "# fulad['annual_return'] = fulad.price.pct_change(360).mul(100)\n",
    "# fulad.plot(subplots = True); plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "104b2c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Growth Rate, Compare with Benchmark, and normalize\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# first_price = fulad.price.iloc[0]    # Another way: first_price2 = fulad.loc['2017-01-01','price']\n",
    "# normalized = fulad.price.div(first_price).mul(100)\n",
    "# normalized.plot()\n",
    "# prices = pd.read_csv(\"Sample for working with time_2_prices.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# normalized_prices = prices.div(prices.iloc[0])\n",
    "# index = pd.read_csv(\"Sample for working with time_2_prices - index.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# prices = pd.concat([prices, index], axis=1).dropna()\n",
    "# normalized_prices = prices.div(prices.iloc[0])\n",
    "# diff = normalized_prices[['fulad','fars','fameli']].sub(normalized_prices['index'], axis = 0)\n",
    "# diff.plot(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "543cf794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Changing the Frequency & Re_index\n",
    "# dates = pd.date_range(start='2016', periods=4, freq='Q')\n",
    "# data = range(1, 5)\n",
    "# quarterly = pd.Series(data=data, index=dates)\n",
    "# monthly = quarterly.asfreq('M')             # consist of Monthly data\n",
    "# monthly = monthly.to_frame('baseline')\n",
    "# monthly['ffill'] = quarterly.asfreq('M', method='ffill')\n",
    "# monthly['bfill'] = quarterly.asfreq(\"M\", method='bfill')\n",
    "# monthly['value'] = quarterly.asfreq(\"M\", fill_value= 0)\n",
    "# print(monthly)\n",
    "\n",
    "# # Re_index\n",
    "# dates = pd.date_range(start='2016', periods=12,freq='M')\n",
    "# quarterly.reindex(dates)   # works like asfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "465b813d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1\n",
    "# start = '2016-1-1'; end = '2016-2-29'\n",
    "# monthly_dates = pd.date_range(start = start, end = end, freq = 'M')\n",
    "# monthly = pd.Series(data = [1,2], index = monthly_dates)\n",
    "# weekly_dates = pd.date_range(start = start, end = end, freq = 'W')\n",
    "# print(monthly.reindex(weekly_dates))\n",
    "# print(monthly.reindex(weekly_dates, method = 'bfill'))\n",
    "# print(monthly.reindex(weekly_dates, method = 'ffill'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6baff1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advanced techniques for changing frequencies  &  Concating\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# fulad.asfreq('M').info()\n",
    "# fulad_resampled = fulad.resample('MS')\n",
    "#checking\n",
    "# fulad.asfreq('MS').equals(fulad.resample('MS').asfreq())\n",
    "\n",
    "# gdp = pd.read_csv(\"GDP.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# gdp_1 = gdp.resample('MS').ffill().add_suffix('_ffill')\n",
    "# gdp_2 = gdp.resample('MS').interpolate().add_suffix('_inter')\n",
    "\n",
    "# # Concating and the importance of setting axis\n",
    "# df = pd.concat([df1, df2],axis=1)\n",
    "# df1 = pd.DataFrame([1, 2, 3], columns=['df1'])\n",
    "# df2 = pd.DataFrame([4, 5, 6], columns=['df2'])\n",
    "# df_without_axis = pd.concat([df1, df2])\n",
    "\n",
    "# pd.concat([gdp_1, gdp_2], axis=1).loc['2015':].plot()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3efe3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Downsizing\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# fulad = fulad.resample('D').asfreq()\n",
    "# fulad_monthly1 = fulad.resample('M').mean()  # if we use 'MS' instead of 'M', it means month start instead of month end\n",
    "# fulad_monthly2 = fulad.resample('M').agg(['mean', 'std'])  # there are also 'first', 'median', and other functions\n",
    "# ax = fulad.plot()\n",
    "# fulad_monthly1.add_suffix('_monthly').plot(ax = ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ccbc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example of downsampling 1\n",
    "# stocks = pd.read_csv(\"stocks.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# stocks.resample('M').mean().plot(subplots=True)\n",
    "# plt.show()\n",
    "\n",
    "# # Example of downsampling 2\n",
    "# gdp_growth = pd.read_csv(\"gdp_growth.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# djia = pd.read_csv(\"djia.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# djia_quarterly = djia.resample('QS').first()\n",
    "# djia_quarterly_return = djia_quarterly.pct_change().mul(100)\n",
    "# data = pd.concat([gdp_growth, djia_quarterly_return], axis = 1)\n",
    "# data.columns = ['gdp','djia']\n",
    "# data.plot(subplots = True); plt.show()\n",
    "\n",
    "# # Example of downsampling 3\n",
    "# sp500 = pd.read_csv(\"sp500.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# daily_returns = sp500.squeeze().pct_change() \n",
    "# stats = daily_returns.resample('M').agg(['mean', 'median', 'std'])\n",
    "# stats.plot(subplots = True); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad9755e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Window Functions\n",
    "# # Rolling windows : with same size\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# Avrg = fulad.rolling(window=30).mean()  # if we use '30D' instead of 30 it uses 30 calendar days instead of business days\n",
    "# fulad.join(Avrg.add_suffix('_mean90')).plot(); plt.show()\n",
    "# fulad['r30'] = Avrg\n",
    "# fulad['r90'] = fulad['price'].rolling(window='90D').mean()\n",
    "# fulad.plot()\n",
    "# information = fulad['price'].rolling(window = 50).agg(['mean','std'])   # we can use fulad.price instead of fulad['price]\n",
    "# rolling = fulad.price.rolling('360D')\n",
    "# q10 = rolling.quantile(0.1).to_frame('quan10')\n",
    "# median = rolling.median().to_frame('med')\n",
    "# q90 = rolling.quantile(0.9).to_frame('quant90')\n",
    "# pd.concat([q10, median, q90], axis = 1).plot(); plt.show()        # we can use .join() instead of concat either.\n",
    "\n",
    "# # Expanding windows : Up to the current date\n",
    "# df = pd.DataFrame({'data': range(5)})\n",
    "# df['expanding sum'] = df.data.expanding().sum()\n",
    "# df['cumulative sum'] = df.data.cumsum()\n",
    "\n",
    "# ret = fulad.price.pct_change()\n",
    "# ret_plus_one = pr.add(1)\n",
    "# fulad['cum_ret'] = ret_plus_one.cumprod().sub(1).mul(100)\n",
    "# fulad['running_min'] = fulad.price.expanding().min()\n",
    "# fulad['running_max'] = fulad.price.expanding().max()\n",
    "# pd.concat([fulad['cum_ret'], fulad['running_max'], fulad['running_min']], axis=1).plot(); plt.show()\n",
    "\n",
    "# def multi_period_return(period_return):\n",
    "#     return np.prod(period_return + 1) - 1    \n",
    "\n",
    "# pr = fulad.price.pct_change()\n",
    "# r = pr.rolling('360D').apply(multi_period_return)   # instead of .mean() we can use more complex functions using .apply()\n",
    "# fulad['Rolling 1 year'] = r.mul(100)\n",
    "# fulad['Rolling 1 year'].plot(), plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc12936a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example 1 of rolling wondows\n",
    "# data = pd.read_csv(\"ozone.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# data['90D'] = data.Ozone.rolling(window = '90D').mean()\n",
    "# data['360D'] = data.Ozone.rolling(window = '360D').mean()\n",
    "# data['2010':].plot(title = 'New York City');  plt.show()\n",
    "\n",
    "# # Example 2 of rolling wondows\n",
    "# data = data.resample('D').interpolate()\n",
    "# rolling = data.Ozone.rolling(window = 360)\n",
    "# data['q10'] = rolling.quantile(0.1).to_frame('q10')\n",
    "# data['q90'] = rolling.quantile(0.9).to_frame('q90')\n",
    "# data.plot(); plt.show()\n",
    "\n",
    "# # Example 1 of Expanding windows\n",
    "# differences = data.diff().dropna()\n",
    "# start_price = data.first('D')\n",
    "# cumulative_sum = start_price.append(differences).cumsum()\n",
    "# print(data.equals(cumulative_sum))\n",
    "\n",
    "# # Example 2 of Expanding windows\n",
    "# investment = 1000\n",
    "# returns = data.pct_change()\n",
    "# returns_plus_one = returns.add(1)\n",
    "# cumulative_return = returns_plus_one.cumprod()\n",
    "# cumulative_return.mul(investment).plot() \n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6cb93373",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Case Study, sns.displot(), generating random_walk, choice, ...\n",
    "\n",
    "# from numpy.random import normal, seed, choice\n",
    "# from scipy.stats import norm\n",
    "# import seaborn as sns\n",
    "# seed(42)\n",
    "# random_returns = normal(loc = 0, scale = 0.01, size = 1000)\n",
    "# sns.displot(data = random_returns, kind='kde')    \n",
    "# return_series = pd.Series(random_returns)\n",
    "# random_prices = return_series.add(1).cumprod().sub(1)\n",
    "# random_prices.mul(100).plot()\n",
    "\n",
    "# fulad = pd.read_csv(\"Sample for working with time.csv\", parse_dates=['date'], index_col= 'date')\n",
    "# fulad['returns'] = fulad.price.pct_change()\n",
    "# sns.displot(fulad.returns.dropna().mul(100), kind='kde')\n",
    "\n",
    "# sample = fulad.returns.dropna()\n",
    "# n_obs = fulad.returns.count()\n",
    "# random_walk = choice(sample, size = n_obs)\n",
    "# random_walk = pd.Series(random_walk, index = sample.index)\n",
    "# start = fulad.price.first('D')\n",
    "# fulad_rand = start.append(random_walk.add(1))\n",
    "# fulad['random_p'] = fulad_rand.cumprod()\n",
    "# fulad[['price', 'random_p']].plot(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Relartionship between time series & sns.jointplot \n",
    "# fulad = pd.read_csv(\"Sample for working with time_2_prices_correl.csv\", parse_dates=['date'], index_col= 'date').dropna()\n",
    "# data_return = fulad.pct_change()\n",
    "# # sns.jointplot(x = 'fulad', y = 'fameli', data=data_return)\n",
    "\n",
    "# stocks = pd.read_csv(\"Sample for working with time_2_prices.csv\", parse_dates=['date'], index_col= 'date').dropna()\n",
    "# data_return = stocks.pct_change()\n",
    "# correl = data_return.corr()\n",
    "# sns.heatmap(correl, annot = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2db8d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Project. The code does not work\n",
    "# nyse = pd.read_excel('listing.xlsx', sheet_name='nyse', na_values='n/a')\n",
    "# nyse.set_index('stock symbol', inplace = True)\n",
    "# nyse.dropna(subset = ['Sector'], inplace = True)\n",
    "# nyse['Market Cap'] /= 1e6\n",
    "# components = nyse.groupby(['Sector'])['Market Cap'].nlargest(1)\n",
    "# components.sort_values(ascending = False)\n",
    "# tickers = components.index.get_level_values('Stock Symbol')\n",
    "# columns = ['Company name', 'Market Cap', 'Last Sale']\n",
    "# component_info = nyse.loc[tickers, columns]\n",
    "# pd.options.display.float_format = \"{:, .2f}\" .format\n",
    "\n",
    "# data = pd.read_csv('stock.csv', parse_dates=['Date'], index_col='Date').loc[:, tickers.tolist()]\n",
    "# shares = components['Market Cap'].div(components['last sale'])\n",
    "# market_cap_series = data.mul(shares)\n",
    "# market_cap_series.first('D').append(market_cap_series.last('D'))\n",
    "# agg_marketcap = market_cap_series.sum(axis = 1)\n",
    "# agg_marketcap(title = \"Market Cap\")\n",
    "# index_market = agg_marketcap.div(agg_marketcap.iloc[0]).mul(100)\n",
    "\n",
    "# # Value contribution by stocks\n",
    "# change = market_cap_series.first('D').append(market_cap_series.last('D'))\n",
    "# change.diff().iloc[-1].sort_values()  # or .loc['2016-12-30']\n",
    "# market_cap = components['Market Cap']\n",
    "# weights = market_cap.div(market_cap.sum())\n",
    "# index_return = (index_market.iloc[-1] / index.iloc[0] - 1) * 100\n",
    "# weighted_return = weights.mul(index_return)\n",
    "# weighted_return.sort_values().plot(kind = 'barh')\n",
    "# data = index_market.to_frame('Index')   # convert index to a pd.DataFrame\n",
    "# data['Sp500'] = pd.read_csv('SP500.csv', parse_dates=['Date'], index_col='Date')\n",
    "# data.SP500 = data.SP500.div(data.SP500.iloc[0], axis = 0).mul(100)\n",
    "\n",
    "# def multi_period_return(r):\n",
    "#     return (np.prod(r+1) - 1) * 100\n",
    "\n",
    "# data.pct_change().rolling('30D').apply(multi_period_return).plot()\n",
    "\n",
    "# daily_return = data.pct_change()\n",
    "# correlations = daily_return.corr()\n",
    "# sns.heatmap(correlations, annot = True)\n",
    "# plt.xticks(rotation = 45)\n",
    "# plt.title('Daily Correlation')\n",
    "# correlations.to_excel(excel_writer = 'correlation.xlsx', sheet_name = 'corr', startrow = 1, startcol = 1)\n",
    "\n",
    "# data.index = data.date.index  # keep only the date component\n",
    "# with pd.ExcelWriter('stock_data.xlsx') as writer:\n",
    "#     corr.to_excel(excel_writer = writer, sheet_name = 'correlations')\n",
    "#     data.to_excel(excel_writer = writer, sheet_name = 'prices')\n",
    "#     data.pct_change().to_excel(excel_writer = writer, sheet_name = 'returns')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbb6f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Similar Examples - part 1\n",
    "# components = listings.loc[tickers, ['Market Capitalization', 'Last Sale']]\n",
    "# no_shares = components['Market Capitalization'].div(components['Last Sale'])\n",
    "# print(no_shares.sort_values(ascending = False))\n",
    "# no_shares = components['Number of Shares']\n",
    "# market_cap = stock_prices.mul(no_shares)\n",
    "# first_value = market_cap.iloc[0]\n",
    "# last_value = market_cap.iloc[-1]\n",
    "# pd.concat([first_value, last_value], axis = 1).plot(kind = 'barh')\n",
    "# plt.show()\n",
    "# raw_index = market_cap_series.sum(axis = 1)\n",
    "# index = raw_index.div(raw_index.iloc[0]).mul(100)\n",
    "# index.plot(title = 'Market-Cap Weighted Index');    plt.show()\n",
    "\n",
    "# # Similar Examples - part 2\n",
    "# components = listings.loc[tickers, ['Market Capitalization', 'Last Sale']]\n",
    "# no_shares = components['Market Capitalization'].div(components['Last Sale'])\n",
    "# no_shares = components['Number of Shares']\n",
    "# market_cap = stock_prices.mul(no_shares)\n",
    "# first_value = market_cap.iloc[0]\n",
    "# last_value = market_cap.iloc[-1]\n",
    "# pd.concat([first_value, last_value], axis = 1).plot(kind = 'barh'); plt.show()\n",
    "# raw_index = market_cap_series.sum(axis = 1)\n",
    "# index = raw_index.div(raw_index.iloc[0]).mul(100)\n",
    "# index.plot(title = 'Market-Cap Weighted Index');   plt.show()\n",
    "\n",
    "\n",
    "# # Similar Examples - part 3\n",
    "# index_return = (index.iloc[-1]/index.iloc[0] - 1) * 100\n",
    "# market_cap = components['Market Capitalization']\n",
    "# weights = market_cap.div(market_cap.sum())\n",
    "# weights.mul(index_return).sort_values().plot(kind = 'barh');   plt.show()\n",
    "# data = index.to_frame('Index')\n",
    "# djia = djia.div(djia[0]).mul(100)\n",
    "# data['DJIA'] = djia\n",
    "# print(data.iloc[-1].div(data.iloc[0]).sub(1).mul(100))\n",
    "# data.plot(); plt.show()\n",
    "\n",
    "# def multi_period_return(r):\n",
    "#     return (np.prod(r+1)-1) * 100\n",
    "\n",
    "# rolling_return_360 = data.pct_change().rolling('360D').apply(multi_period_return)\n",
    "# rolling_return_360.plot(title = 'Rolling 360D Return');     plt.show()\n",
    "\n",
    "# # Similar Examples - part 4\n",
    "# correlations = stock_prices.pct_change().corr()\n",
    "# sns.heatmap(correlations, annot = True)\n",
    "# plt.title('Daily Return Correlations'); plt.show()\n",
    "# data = stock_prices.join(index);    print(data.info())\n",
    "# returns = data.pct_change()\n",
    "# with pd.ExcelWriter('data.xls') as writer:\n",
    "#     data.to_excel(excel_writer = writer, sheet_name = 'data')\n",
    "#     returns.to_excel(excel_writer = writer, sheet_name = 'returns')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
